{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c8ce6c-938e-447b-8726-48dcbcf3d945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'combined_extracted_product_details.csv' created with 19 products processed.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_tasting_notes_from_blend(body_html):\n",
    "    \"\"\"\n",
    "    Extracts tasting/flavour notes for blend products.\n",
    "    \n",
    "    First, it looks for an <em> tag and returns its text if found.\n",
    "    If no <em> tag is present, it falls back to checking the first <p> tag \n",
    "    for a vertical bar (\"|\") and returning the text after it.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(body_html, 'html.parser')\n",
    "    # Try to find all <em> tags\n",
    "    em_tag = soup.find('em')\n",
    "    if em_tag:\n",
    "        return em_tag.get_text().strip()\n",
    "    \n",
    "    # Fallback: look in the first <p> tag for a vertical bar.\n",
    "    first_p = soup.find('p')\n",
    "    if first_p:\n",
    "        text = first_p.get_text(separator=\" \", strip=True)\n",
    "        if \"|\" in text:\n",
    "            parts = text.split(\"|\")\n",
    "            if len(parts) > 1:\n",
    "                return parts[1].strip()\n",
    "    return \"\"\n",
    "\n",
    "def extract_cupping_notes(body_html):\n",
    "    \"\"\"\n",
    "    Extracts cupping notes for single origin products by checking for the first occurrence \n",
    "    of either an <em> or <i> tag.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(body_html, 'html.parser')\n",
    "    note_tag = soup.find(['em', 'i'])\n",
    "    if note_tag:\n",
    "        return note_tag.get_text().strip()\n",
    "    return \"\"\n",
    "\n",
    "def extract_table_info(body_html):\n",
    "    \"\"\"\n",
    "    Extracts table information for Region, Varietal, Process, and Altitude.\n",
    "    \n",
    "    The function finds the first <table> element and processes its second <td> cell.\n",
    "    \n",
    "    - For many products, the cell splits into four parts:\n",
    "         [Region, Varietal, Process, Altitude]\n",
    "    - For products like \"Midnight Run\" where the table splits into five parts,\n",
    "         we assume the parts represent [Country, Farms, Varietals, Process, Altitude]\n",
    "         and we map as follows:\n",
    "             Region ← part 0 (Country)\n",
    "             Varietal ← part 2 (Varietals)\n",
    "             Process ← part 3\n",
    "             Altitude ← part 4\n",
    "    \"\"\"\n",
    "    result = {\"Region\": \"\", \"Varietal\": \"\", \"Process\": \"\", \"Altitude\": \"\"}\n",
    "    soup = BeautifulSoup(body_html, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    if table:\n",
    "        tds = table.find_all('td')\n",
    "        if len(tds) >= 2:\n",
    "            # Use \"|\" as a temporary separator for <br> tags.\n",
    "            cell_text = tds[1].get_text(separator=\"|\")\n",
    "            parts = [part.strip() for part in cell_text.split(\"|\") if part.strip() != \"\"]\n",
    "            # Remove any leading colon from each part.\n",
    "            parts = [part.lstrip(\":\").strip() for part in parts]\n",
    "            if len(parts) == 5:\n",
    "                result[\"Region\"] = parts[0]\n",
    "                result[\"Varietal\"] = parts[2]\n",
    "                result[\"Process\"] = parts[3]\n",
    "                result[\"Altitude\"] = parts[4]\n",
    "            elif len(parts) >= 4:\n",
    "                result[\"Region\"] = parts[0]\n",
    "                result[\"Varietal\"] = parts[1]\n",
    "                result[\"Process\"] = parts[2]\n",
    "                result[\"Altitude\"] = parts[3]\n",
    "    return result\n",
    "\n",
    "def extract_roast_type(body_html):\n",
    "    \"\"\"\n",
    "    Extracts roast type from the first <p> tag in the body_html.\n",
    "    It looks for a vertical bar (\"|\") and takes the text after it,\n",
    "    then normalizes the value to \"espresso\", \"filter\", or \"omni\".\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(body_html, 'html.parser')\n",
    "    first_p = soup.find('p')\n",
    "    if first_p:\n",
    "        text = first_p.get_text(separator=\" \", strip=True)\n",
    "        if \"|\" in text:\n",
    "            parts = text.split(\"|\")\n",
    "            roast = parts[1].strip().lower()\n",
    "            if \"espresso\" in roast:\n",
    "                return \"espresso\"\n",
    "            elif \"filter\" in roast:\n",
    "                return \"filter\"\n",
    "            elif \"omni\" in roast:\n",
    "                return \"omni\"\n",
    "    return \"\"\n",
    "\n",
    "def process_products(url, csv_filename):\n",
    "    # Fetch the JSON from the URL.\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching products:\", response.status_code)\n",
    "        return\n",
    "    data = response.json()\n",
    "    products = data.get(\"products\", [])\n",
    "\n",
    "    # Define CSV columns.\n",
    "    fieldnames = [\n",
    "        \"Title\",\n",
    "        \"Primary Image URL\",\n",
    "        \"Availability\",\n",
    "        \"Roast Type\",\n",
    "        \"Flavour Notes\",\n",
    "        \"Region\",\n",
    "        \"Varietal\",\n",
    "        \"Process\",\n",
    "        \"Altitude\",\n",
    "        \"Vendor\",\n",
    "        \"Product Type\",\n",
    "        \"Variant Part 1\",\n",
    "        \"Variant Part 2\",\n",
    "        \"Variant Part 3\",\n",
    "        \"Variant Price\",\n",
    "        \"Variant Availability\"\n",
    "    ]\n",
    "\n",
    "    with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for product in products:\n",
    "            title = product.get(\"title\", \"\")\n",
    "            vendor = product.get(\"vendor\", \"\")\n",
    "            product_type = product.get(\"product_type\", \"\")\n",
    "            images = product.get(\"images\", [])\n",
    "            primary_image_url = images[0][\"src\"] if images else \"\"\n",
    "            product_availability = any(variant.get(\"available\", False) for variant in product.get(\"variants\", []))\n",
    "            availability = \"Available\" if product_availability else \"Not Available\"\n",
    "            body_html = product.get(\"body_html\", \"\")\n",
    "\n",
    "            # Extract roast type.\n",
    "            roast_type = extract_roast_type(body_html)\n",
    "            \n",
    "            # Choose note extraction based on product type.\n",
    "            if \"blend\" in product_type.lower():\n",
    "                notes = extract_tasting_notes_from_blend(body_html)\n",
    "            elif \"single origin\" in product_type.lower():\n",
    "                notes = extract_cupping_notes(body_html)\n",
    "            else:\n",
    "                notes = \"\"\n",
    "\n",
    "            # Extract table info.\n",
    "            table_info = extract_table_info(body_html)\n",
    "            region = table_info.get(\"Region\", \"\")\n",
    "            varietal = table_info.get(\"Varietal\", \"\")\n",
    "            process_field = table_info.get(\"Process\", \"\")\n",
    "            altitude = table_info.get(\"Altitude\", \"\")\n",
    "\n",
    "            # Loop through each variant.\n",
    "            for variant in product.get(\"variants\", []):\n",
    "                variant_name = variant.get(\"title\", \"\")\n",
    "                # Only process variants that include \"Whole Bean\" (case-insensitive)\n",
    "                # and skip variants containing \"(Wholesale)\".\n",
    "                if \"whole bean\" not in variant_name.lower():\n",
    "                    continue\n",
    "                if \"(wholesale)\" in variant_name.lower():\n",
    "                    continue\n",
    "\n",
    "                parts = [p.strip() for p in variant_name.split(\" / \")]\n",
    "                if len(parts) < 3:\n",
    "                    parts += [\"\"] * (3 - len(parts))\n",
    "                variant_part1, variant_part2, variant_part3 = parts[:3]\n",
    "\n",
    "                variant_price = variant.get(\"price\", \"\")\n",
    "                variant_availability = \"Available\" if variant.get(\"available\", False) else \"Not Available\"\n",
    "\n",
    "                row = {\n",
    "                    \"Title\": title,\n",
    "                    \"Primary Image URL\": primary_image_url,\n",
    "                    \"Availability\": availability,\n",
    "                    \"Roast Type\": roast_type,\n",
    "                    \"Flavour Notes\": notes,\n",
    "                    \"Region\": region,\n",
    "                    \"Varietal\": varietal,\n",
    "                    \"Process\": process_field,\n",
    "                    \"Altitude\": altitude,\n",
    "                    \"Vendor\": vendor,\n",
    "                    \"Product Type\": product_type,\n",
    "                    \"Variant Part 1\": variant_part1,\n",
    "                    \"Variant Part 2\": variant_part2,\n",
    "                    \"Variant Part 3\": variant_part3,\n",
    "                    \"Variant Price\": variant_price,\n",
    "                    \"Variant Availability\": variant_availability\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "\n",
    "    print(f\"CSV file '{csv_filename}' created with {len(products)} products processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # URL for the Dutch Colony products JSON.\n",
    "    url = \"https://www.dutchcolony.sg/collections/coffee-2/products.json\"\n",
    "    csv_filename = \"combined_extracted_product_details.csv\"\n",
    "    process_products(url, csv_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
