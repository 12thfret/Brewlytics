{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c8ce6c-938e-447b-8726-48dcbcf3d945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to ppp_beans.csv\n",
      "Data scraped and saved to ppp_beans.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_line_value(text, label):\n",
    "    \"\"\"\n",
    "    Searches for `label` ignoring whether there's a colon or not,\n",
    "    returning everything after `label` up to the next newline.\n",
    "    \"\"\"\n",
    "    # Example pattern:\n",
    "    #   \"We Taste\" + optional anything + optional colon + optional space + (capture rest of line)\n",
    "    pattern = rf\"{label}.*?:?\\s*(.*)\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).split('\\n', 1)[0].strip()\n",
    "    return \"\"\n",
    "\n",
    "def extract_country_region(body_html):\n",
    "    soup = BeautifulSoup(body_html, 'html.parser')\n",
    "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    return extract_line_value(text, \"Country/Region\")\n",
    "\n",
    "def extract_varietal(body_html):\n",
    "    soup = BeautifulSoup(body_html, 'html.parser')\n",
    "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    return extract_line_value(text, \"Varietal\")\n",
    "\n",
    "def extract_processing(body_html):\n",
    "    soup = BeautifulSoup(body_html, 'html.parser')\n",
    "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    return extract_line_value(text, \"Processing\")\n",
    "\n",
    "def extract_flavour_notes(body_html):\n",
    "    soup = BeautifulSoup(body_html, 'html.parser')\n",
    "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    return extract_line_value(text, \"We Taste\")\n",
    "\n",
    "def parse_variant_title(variant_title):\n",
    "    parts = variant_title.split(\" / \", maxsplit=1)\n",
    "    if len(parts) == 2:\n",
    "        return parts[0].strip(), parts[1].strip()\n",
    "    return variant_title.strip(), \"\"\n",
    "\n",
    "def scrape_ppp_beans(url, csv_filename):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to retrieve data\")\n",
    "        return\n",
    "\n",
    "    data = response.json()\n",
    "    products = data.get(\"products\", [])\n",
    "\n",
    "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = [\n",
    "            \"Product ID\", \"Product Title\", \"Variant ID\", \"Variant Weight\", \"Variant Detail\",\n",
    "            \"Price\", \"SKU\", \"Image URL\",\n",
    "            \"Country\", \"Varietal\", \"Processing\", \"Flavour Notes\",\n",
    "            # Optional extra fields:\n",
    "            # \"Elevation\", \"Harvest\", ...\n",
    "        ]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for product in products:\n",
    "            product_id = product.get(\"id\")\n",
    "            product_title = product.get(\"title\")\n",
    "            body_html = product.get(\"body_html\", \"\")\n",
    "\n",
    "            # Extract info\n",
    "            country_region = extract_country_region(body_html)\n",
    "            varietal = extract_varietal(body_html)\n",
    "            processing = extract_processing(body_html)\n",
    "            flavour_notes = extract_flavour_notes(body_html)\n",
    "            \n",
    "            # Optional extra:\n",
    "            # elevation = extract_line_value(soup_text, \"Elevation\")\n",
    "            # harvest = extract_line_value(soup_text, \"Harvest\")\n",
    "\n",
    "            images = product.get(\"images\", [])\n",
    "            image_url = images[0].get(\"src\", \"N/A\") if images else \"N/A\"\n",
    "\n",
    "            variants = product.get(\"variants\", [])\n",
    "            for variant in variants:\n",
    "                variant_id = variant.get(\"id\")\n",
    "                vtitle = variant.get(\"title\", \"\")\n",
    "                weight, detail = parse_variant_title(vtitle)\n",
    "                # Only keep \"Whole Beans\" if thatâ€™s your requirement:\n",
    "                if detail != \"Whole Beans\":\n",
    "                    continue\n",
    "\n",
    "                row = {\n",
    "                    \"Product ID\": product_id,\n",
    "                    \"Product Title\": product_title,\n",
    "                    \"Variant ID\": variant_id,\n",
    "                    \"Variant Weight\": weight,\n",
    "                    \"Variant Detail\": detail,\n",
    "                    \"Price\": variant.get(\"price\"),\n",
    "                    \"SKU\": variant.get(\"sku\"),\n",
    "                    \"Image URL\": image_url,\n",
    "                    \"Country\": country_region,\n",
    "                    \"Varietal\": varietal,\n",
    "                    \"Processing\": processing,\n",
    "                    \"Flavour Notes\": flavour_notes\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "\n",
    "    print(f\"Data scraped and saved to {csv_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://pppcoffee.com/collections/beans/products.json\"\n",
    "    csv_filename = \"ppp_beans.csv\"\n",
    "    scrape_ppp_beans(url, csv_filename)\n",
    "    print(f\"Data scraped and saved to {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
