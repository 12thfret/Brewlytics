{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1c8ce6c-938e-447b-8726-48dcbcf3d945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved to prodigal_roasters_wholebeans.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_process(body_text):\n",
    "    \"\"\"\n",
    "    Look for text after 'Process:' and up to either 'Varietal:' or the end.\n",
    "    Example match: 'Washed'\n",
    "    \"\"\"\n",
    "    match = re.search(r\"Process:\\s*(.*?)\\s*(?=Varietal:|$)\", body_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "def extract_varietal(body_text):\n",
    "    \"\"\"\n",
    "    Look for text after 'Varietal:' and up to 'Tasting Notes:' or the end.\n",
    "    Example match: 'Pink Bourbon'\n",
    "    \"\"\"\n",
    "    match = re.search(r\"Varietal:\\s*(.*?)\\s*(?=Tasting Notes:|$)\", body_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "def extract_tasting_notes(body_text):\n",
    "    \"\"\"\n",
    "    Look for text after 'Tasting Notes:' to the end of the line.\n",
    "    Then remove trailing text such as \"Omni Roast, available as...\" if present.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"Tasting Notes:\\s*(.*)\", body_text, re.IGNORECASE)\n",
    "    if not match:\n",
    "        return \"\"\n",
    "\n",
    "    notes = match.group(1).strip()\n",
    "    \n",
    "    # 1) Remove anything after \"Omni Roast\" (case-insensitive):\n",
    "    notes = re.sub(r\"(?i)\\b(omni roast|filter roast).*\", \"\", notes).strip()\n",
    "\n",
    "    # 2) Optionally also remove \"Filter Roast\" if you want:\n",
    "    # notes = re.sub(r\"(?i)\\bfilter roast.*\", \"\", notes).strip()\n",
    "\n",
    "    return notes\n",
    "\n",
    "def parse_variant_title(variant_title):\n",
    "    \"\"\"\n",
    "    Splits a variant title like \"200g / Whole Beans\" into (weight, detail).\n",
    "    If the format doesn't match, fallback to (variant_title, \"\").\n",
    "    \"\"\"\n",
    "    parts = variant_title.split(\" / \", maxsplit=1)\n",
    "    if len(parts) == 2:\n",
    "        return parts[0].strip(), parts[1].strip()\n",
    "    return variant_title.strip(), \"\"\n",
    "\n",
    "def scrape_prodigal_beans(url, csv_filename):\n",
    "    # 1. Fetch JSON data\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to retrieve data\")\n",
    "        return\n",
    "    data = response.json()\n",
    "    products = data.get(\"products\", [])\n",
    "\n",
    "    # 2. Prepare CSV\n",
    "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = [\n",
    "             \"Product Title\", \"Variant Weight\",\n",
    "            \"Variant Detail\", \"Price\", \"Process\", \"Varietal\", \"Tasting Notes\"\n",
    "        ]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # 3. Loop through products\n",
    "        for product in products:\n",
    "            product_id = product.get(\"id\")\n",
    "            product_title = product.get(\"title\")\n",
    "            body_html = product.get(\"body_html\", \"\")\n",
    "\n",
    "            # Convert HTML to plain text for easier regex\n",
    "            soup = BeautifulSoup(body_html, 'html.parser')\n",
    "            body_text = soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "            # Extract fields\n",
    "            process_info = extract_process(body_text)\n",
    "            varietal_info = extract_varietal(body_text)\n",
    "            tasting_notes = extract_tasting_notes(body_text)\n",
    "\n",
    "            # 4. Loop through variants\n",
    "            for variant in product.get(\"variants\", []):\n",
    "                variant_id = variant.get(\"id\")\n",
    "                variant_title = variant.get(\"title\", \"\")\n",
    "                weight, detail = parse_variant_title(variant_title)\n",
    "                \n",
    "                # We only keep “Whole Beans”\n",
    "                if detail.lower() != \"whole beans\":\n",
    "                    continue\n",
    "\n",
    "                row = {\n",
    "                    \"Product Title\": product_title,\n",
    "                    \"Variant Weight\": weight,\n",
    "                    \"Variant Detail\": detail,\n",
    "                    \"Price\": variant.get(\"price\", \"\"),\n",
    "                    \"Process\": process_info,\n",
    "                    \"Varietal\": varietal_info,\n",
    "                    \"Tasting Notes\": tasting_notes\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "\n",
    "    print(f\"Data scraped and saved to {csv_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://prodigalroasters.com/collections/coffee-beans-singapore/products.json\"\n",
    "    csv_filename = \"prodigal_roasters_wholebeans.csv\"\n",
    "    scrape_prodigal_beans(url, csv_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
