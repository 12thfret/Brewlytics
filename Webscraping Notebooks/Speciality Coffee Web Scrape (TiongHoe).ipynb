{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "908bb730-33eb-434f-83d5-99c2eee3b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "# Base URLs\n",
    "collection_url = \"https://tionghoe.com/collections/roasted-beans\"\n",
    "base_product_url = \"https://tionghoe.com\"\n",
    "\n",
    "# Headers to mimic a browser visit\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/89.0.4389.82 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Output CSV file\n",
    "output_file = \"tionghoe.csv\"\n",
    "\n",
    "# ---- PART 1: Scrape Variants (Title, Price, Weight) ----\n",
    "\n",
    "def extract_weight(title):\n",
    "    \"\"\"\n",
    "    Extract weight (e.g., '250g', '1kg') from the variant title.\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\d+\\s?[gG]|1\\s?[kK][gG])', title)\n",
    "    return match.group(0) if match else 'N/A'\n",
    "\n",
    "def clean_variant_title(title):\n",
    "    \"\"\"\n",
    "    Remove weight from the variant title.\n",
    "    \"\"\"\n",
    "    return re.sub(r'(\\d+\\s?[gG]|1\\s?[kK][gG])', '', title).strip()\n",
    "\n",
    "def scrape_variants():\n",
    "    variant_data = []\n",
    "    response = requests.get(collection_url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    meta_data_script = soup.find(\"script\", string=lambda t: t and \"var meta =\" in t)\n",
    "    if meta_data_script:\n",
    "        meta_data_text = meta_data_script.string\n",
    "        start_index = meta_data_text.find('{\"products\":')\n",
    "        end_index = meta_data_text.rfind(\"};\") + 1\n",
    "        valid_json_text = meta_data_text[start_index:end_index]\n",
    "\n",
    "        try:\n",
    "            meta = json.loads(valid_json_text)\n",
    "            for product in meta.get(\"products\", []):\n",
    "                product_id = product.get(\"id\", \"N/A\")\n",
    "\n",
    "                for variant in product.get(\"variants\", []):\n",
    "                    variant_price = variant.get(\"price\", 0) / 100\n",
    "                    variant_name = variant.get(\"name\", \"N/A\")\n",
    "\n",
    "                    # Only keep variants with \"Whole Beans\" in the title\n",
    "                    if \"Whole Beans\" in variant_name:\n",
    "                        variant_url = f\"https://tionghoe.com/products/{product_id}\"\n",
    "\n",
    "                        # Extract weight and clean title\n",
    "                        weight = extract_weight(variant_name)\n",
    "                        cleaned_title = clean_variant_title(variant_name)\n",
    "\n",
    "                        variant_data.append({\n",
    "                            \"Variant Title\": cleaned_title,\n",
    "                            \"Weight\": weight,\n",
    "                            \"Product URL\": variant_url,\n",
    "                            \"Price (SGD)\": f\"S${variant_price:.2f}\"\n",
    "                        })\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "    return variant_data\n",
    "\n",
    "# ---- PART 2: Scrape Product Details (Flavour, Body, Region, etc.) ----\n",
    "\n",
    "def scrape_product_details():\n",
    "    response = requests.get(collection_url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    product_cards = soup.select(\"span.product-card__title\")\n",
    "\n",
    "    product_data = []\n",
    "    for card in product_cards:\n",
    "        title_element = card.find(\"a\", class_=\"bold\")\n",
    "        title = title_element.text.strip() if title_element else \"N/A\"\n",
    "        product_url = title_element[\"href\"] if title_element else \"N/A\"\n",
    "        full_product_url = f\"{base_product_url}{product_url}\"\n",
    "\n",
    "        # Initialize relevant product fields\n",
    "        product_details = {\n",
    "            \"Product Title\": title,\n",
    "            \"Product URL\": full_product_url,\n",
    "            \"Flavor\": \"N/A\",\n",
    "            \"Body\": \"N/A\",\n",
    "            \"Aftertaste\": \"N/A\",\n",
    "            \"Region\": \"N/A\",\n",
    "            \"Varietal\": \"N/A\",\n",
    "            \"Process\": \"N/A\",\n",
    "            \"Product Image URL\": \"N/A\"  # New field for image URL\n",
    "        }\n",
    "\n",
    "        print(f\"Scraping: {full_product_url}\")\n",
    "        product_response = requests.get(full_product_url, headers=HEADERS)\n",
    "        product_soup = BeautifulSoup(product_response.text, \"html.parser\")\n",
    "\n",
    "        # Extract flavor, body, and aftertaste from feature chart\n",
    "        feature_chart = product_soup.find(\"div\", class_=\"feature-chart__table\")\n",
    "        if feature_chart:\n",
    "            for feature in [\"Flavor\", \"Body\", \"Aftertaste\"]:\n",
    "                try:\n",
    "                    product_details[feature] = feature_chart.find(\"div\", string=feature).find_next_sibling(\"div\").text.strip()\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "\n",
    "        # Extract description details\n",
    "        description_div = product_soup.find(\"div\", class_=\"section-stack__intro\")\n",
    "        if description_div:\n",
    "            description_text = description_div.find(\"p\").get_text(separator=\" \")\n",
    "\n",
    "            for field in [\"Region\", \"Varietal\", \"Process\"]:\n",
    "                try:\n",
    "                    start = description_text.index(f\"{field}:\") + len(f\"{field}:\")\n",
    "                    end = description_text.find(\":\", start)\n",
    "                    product_details[field] = description_text[start:end].strip()\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        # --- NEW: Extract Product Image URL from meta tags ---\n",
    "        image_meta = product_soup.find(\"meta\", property=\"og:image:secure_url\")\n",
    "        if not image_meta:\n",
    "            image_meta = product_soup.find(\"meta\", property=\"og:image\")\n",
    "        if image_meta:\n",
    "            product_details[\"Product Image URL\"] = image_meta.get(\"content\", \"N/A\")\n",
    "        else:\n",
    "            product_details[\"Product Image URL\"] = \"N/A\"\n",
    "\n",
    "        product_data.append(product_details)\n",
    "        print(f\"Scraped details for: {title}\")\n",
    "\n",
    "    return product_data\n",
    "\n",
    "# ---- PART 3: Fuzzy Matching and Combining Data ----\n",
    "\n",
    "def similar(a, b):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two strings.\n",
    "    \"\"\"\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def combine_and_export():\n",
    "    variants = scrape_variants()\n",
    "    products = scrape_product_details()\n",
    "\n",
    "    combined_data = []\n",
    "\n",
    "    for variant in variants:\n",
    "        variant_title = variant[\"Variant Title\"]\n",
    "\n",
    "        # Find the best matching product based on title similarity\n",
    "        best_match = None\n",
    "        highest_similarity = 0\n",
    "\n",
    "        for product in products:\n",
    "            product_title = product[\"Product Title\"]\n",
    "            similarity_score = similar(variant_title.lower(), product_title.lower())\n",
    "\n",
    "            if similarity_score > highest_similarity:\n",
    "                highest_similarity = similarity_score\n",
    "                best_match = product\n",
    "\n",
    "        # Apply a similarity threshold (e.g., >0.6 for a match)\n",
    "        if highest_similarity > 0.6 and best_match:\n",
    "            combined_entry = {\n",
    "                \"Variant Title\": variant_title,\n",
    "                \"Weight\": variant[\"Weight\"],\n",
    "                \"Product Title\": best_match[\"Product Title\"],\n",
    "                \"Product URL\": variant[\"Product URL\"],\n",
    "                \"Price (SGD)\": variant[\"Price (SGD)\"],\n",
    "                \"Flavor\": best_match.get(\"Flavor\", \"N/A\"),\n",
    "                \"Body\": best_match.get(\"Body\", \"N/A\"),\n",
    "                \"Aftertaste\": best_match.get(\"Aftertaste\", \"N/A\"),\n",
    "                \"Region\": best_match.get(\"Region\", \"N/A\"),\n",
    "                \"Varietal\": best_match.get(\"Varietal\", \"N/A\"),\n",
    "                \"Process\": best_match.get(\"Process\", \"N/A\"),\n",
    "                \"Product Image URL\": best_match.get(\"Product Image URL\", \"N/A\")\n",
    "            }\n",
    "            combined_data.append(combined_entry)\n",
    "\n",
    "    # Write combined data to CSV\n",
    "    with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        fieldnames = [\n",
    "            \"Variant Title\", \"Weight\", \"Product Title\", \"Product URL\", \"Price (SGD)\", \"Flavor\", \"Body\",\n",
    "            \"Aftertaste\", \"Region\", \"Varietal\", \"Process\", \"Product Image URL\"\n",
    "        ]\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(combined_data)\n",
    "\n",
    "    print(f\"Fuzzy matched data with weight successfully written to {output_file}\")\n",
    "\n",
    "# ---- RUN THE SCRAPER ----\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    combine_and_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
