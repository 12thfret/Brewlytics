{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ea1c6e84-1281-4bb6-a297-48cb03ffc575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to 'products_with_details.csv'.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_timestamp(timestamp):\n",
    "    \"\"\"Convert timestamp to a cleaner format: 'YYYY-MM-DD'.\"\"\"\n",
    "    try:\n",
    "        dt = datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        return dt.strftime(\"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        return timestamp  # Return the original if it can't be parsed\n",
    "\n",
    "def extract_coffee_details(body_text):\n",
    "    \"\"\"Extract coffee details dynamically from body text.\"\"\"\n",
    "    fields = {\n",
    "        \"Region\": None,\n",
    "        \"Variety\": None,\n",
    "        \"Elevation\": None,\n",
    "        \"Processing\": None,\n",
    "        \"Roast profile\": None,\n",
    "        \"Flavour notes\": None,\n",
    "        \"Acidity\": None,\n",
    "        \"Body\": None,\n",
    "        \"Tasting Experience\": None,\n",
    "        \"Farm Information\": None,  # New field\n",
    "        \"Moisture content of Green Coffee\": None,  # New field\n",
    "        \"Packaging\": None  # New field\n",
    "    }\n",
    "    \n",
    "    patterns = {\n",
    "        \"Region\": r\"Region:\\s*([\\w\\s.,&-]+)\",\n",
    "        \"Variety\": r\"Variety:\\s*([\\w\\s.,&-]+)\",\n",
    "        \"Elevation\": r\"Elevation:\\s*([\\w\\s.,&-]+)\",\n",
    "        \"Processing\": r\"Processing:\\s*([\\w\\s.,&-]+)\",\n",
    "        \"Roast profile\": r\"Roast profile:\\s*([\\w\\s.,&-]+)\",\n",
    "        \"Flavour notes\": r\"Flavour notes:\\s*([\\w\\s.,&-]+)\",\n",
    "        \"Acidity\": r\"Acidity:\\s*([\\w\\s.,&-]+)\",\n",
    "        \"Body\": r\"Body:\\s*([\\w\\s.,&-]+)\",\n",
    "        \"Tasting Experience\": r\"Tasting experience:\\s*([\\w\\s.,&-]+)\",\n",
    "        \"Farm Information\": r\"Farm Information:\\s*([\\w\\s.,&-]+)\",\n",
    "        \"Moisture content of Green Coffee\": r\"Moisture content of Green Coffee:\\s*([\\w\\s.,&-]+)\",\n",
    "        \"Packaging\": r\"Packaging:\\s*([\\w\\s.,&-]+)\"\n",
    "    }\n",
    "    \n",
    "    # Clean the HTML content\n",
    "    soup = BeautifulSoup(body_text, \"html.parser\")\n",
    "    plain_text = soup.get_text()\n",
    "\n",
    "    for field, pattern in patterns.items():\n",
    "        match = re.search(pattern, plain_text, re.IGNORECASE | re.DOTALL)\n",
    "        if match:\n",
    "            fields[field] = match.group(1).strip()\n",
    "\n",
    "    return fields\n",
    "\n",
    "def fetch_products(page):\n",
    "    \"\"\"Fetch products from the paginated API.\"\"\"\n",
    "    url = f\"https://cowpressocoffee.sg/collections/frontpage/products.json?page={page}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get(\"products\", [])\n",
    "    return []\n",
    "\n",
    "def parse_product(product):\n",
    "    \"\"\"Extract and clean details from a product dictionary.\"\"\"\n",
    "    description_html = product.get(\"body_html\", \"\")\n",
    "    extracted_details = extract_coffee_details(description_html)\n",
    "    \n",
    "    parsed_products = []\n",
    "    \n",
    "    # Add rows for each variant\n",
    "    variants = product.get(\"variants\", [])\n",
    "    image_url = product.get(\"images\", [{}])[0].get(\"src\", \"\")  # Use the first image URL for all variants\n",
    "    \n",
    "    for variant in variants:\n",
    "        parsed_products.append({\n",
    "            \"Product ID\": product.get(\"id\"),\n",
    "            \"Title\": product.get(\"title\"),\n",
    "            \"Vendor\": product.get(\"vendor\"),\n",
    "            \"Created At\": clean_timestamp(product.get(\"created_at\", \"\")),\n",
    "            \"Updated At\": clean_timestamp(product.get(\"updated_at\", \"\")),\n",
    "            \"Variant ID\": variant.get(\"id\"),\n",
    "            \"Variant Title\": variant.get(\"title\"),\n",
    "            \"Variant Price\": variant.get(\"price\"),\n",
    "            \"Image URL\": image_url,\n",
    "            **extracted_details,\n",
    "        })\n",
    "\n",
    "    return parsed_products\n",
    "\n",
    "def write_to_csv(data, file_name=\"products_with_details.csv\"):\n",
    "    \"\"\"Write the flattened data into a CSV file.\"\"\"\n",
    "    with open(file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file, quoting=csv.QUOTE_MINIMAL, escapechar=\"\\\\\")\n",
    "        # Write header\n",
    "        writer.writerow([\n",
    "            \"Product ID\", \"Title\", \n",
    "            \"Vendor\", \"Created At\", \"Updated At\", \"Variant ID\",\n",
    "            \"Variant Title\", \"Variant Price\", \"Image URL\",\n",
    "            \"Region\", \"Variety\", \"Elevation\", \"Processing\", \n",
    "            \"Roast profile\", \"Flavour notes\", \"Acidity\", \"Body\",\n",
    "            \"Tasting Experience\", \"Farm Information\", \n",
    "            \"Moisture content of Green Coffee\", \"Packaging\"\n",
    "        ])\n",
    "        # Write product data\n",
    "        for product in data:\n",
    "            writer.writerow([\n",
    "                product[\"Product ID\"], product[\"Title\"], product[\"Vendor\"],\n",
    "                product[\"Created At\"], product[\"Updated At\"], product[\"Variant ID\"],\n",
    "                product[\"Variant Title\"], product[\"Variant Price\"], product[\"Image URL\"],\n",
    "                product[\"Region\"], product[\"Variety\"], product[\"Elevation\"],\n",
    "                product[\"Processing\"], product[\"Roast profile\"], product[\"Flavour notes\"],\n",
    "                product[\"Acidity\"], product[\"Body\"], product[\"Tasting Experience\"],\n",
    "                product[\"Farm Information\"], product[\"Moisture content of Green Coffee\"],\n",
    "                product[\"Packaging\"]\n",
    "            ])\n",
    "\n",
    "\n",
    "def scrape_and_export_to_csv():\n",
    "    \"\"\"Main function to scrape and export data to a CSV file.\"\"\"\n",
    "    page = 1\n",
    "    all_products = []\n",
    "    \n",
    "    while True:\n",
    "        products = fetch_products(page)\n",
    "        if not products:  # Break if no products are found\n",
    "            break\n",
    "\n",
    "        for product in products:\n",
    "            parsed_products = parse_product(product)\n",
    "            all_products.extend(parsed_products)\n",
    "        \n",
    "        page += 1\n",
    "\n",
    "    # Write all collected data to a CSV file\n",
    "    write_to_csv(all_products)\n",
    "    print(\"Data exported to 'products_with_details.csv'.\")\n",
    "\n",
    "# Run the scraper and export\n",
    "scrape_and_export_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "5ae1f623-6c09-4405-a746-575fd5f86751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV written to cowpresso.csv\n"
     ]
    }
   ],
   "source": [
    "def clean_csv(input_file, output_file):\n",
    "    \"\"\"Cleans up the CSV file based on specific rules.\"\"\"\n",
    "    # Open the input file for reading\n",
    "    with open(input_file, mode=\"r\", encoding=\"utf-8\") as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        fieldnames = reader.fieldnames\n",
    "\n",
    "        # Drop the specified columns\n",
    "        columns_to_drop = [\n",
    "            \"Tasting Experience\", \"Farm Information\", \n",
    "            \"Moisture content of Green Coffee\", \"Packaging\", \"Body\"\n",
    "        ]\n",
    "        fieldnames = [col for col in fieldnames if col not in columns_to_drop]\n",
    "\n",
    "        # Open the output file for writing\n",
    "        with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "\n",
    "            # Write the header\n",
    "            writer.writeheader()\n",
    "\n",
    "            for row in reader:\n",
    "                # Apply the cleaning rules\n",
    "                misplaced_headers = [\n",
    "                    \"Elevation\", \"Variety\", \"Processing\", \"Roast profile\",\n",
    "                    \"Flavour notes\", \"Acidity\", \"Body\", \"Tasting notes\", \n",
    "                    \"District\", \"Farm\", \"Packaging\", \"Type of Soil\", \"Soil Type\", \"MASL\", \"Varietal\", \"Flavour\", \n",
    "                    \"Average Annual Rainfall\", \"notes\", \"this crop\", \"Roast Level\", \"Process\"\n",
    "                ]\n",
    "\n",
    "                for key, value in row.items():\n",
    "                    if value:  # Only process non-empty fields\n",
    "                        # Handle concatenated misplaced headers\n",
    "                        for header in misplaced_headers:\n",
    "                            # Insert space before misplaced headers if needed\n",
    "                            value = re.sub(\n",
    "                                rf\"(?<!\\s){header}\",\n",
    "                                rf\" {header}\",\n",
    "                                value,\n",
    "                                flags=re.IGNORECASE\n",
    "                            )\n",
    "                            # Remove the header text if it's misplaced in the value\n",
    "                            value = re.sub(\n",
    "                                rf\"\\b{header}\\b\",\n",
    "                                \"\",\n",
    "                                value,\n",
    "                                flags=re.IGNORECASE\n",
    "                            )\n",
    "\n",
    "                        # Special cleaning for \"Elevation\" column\n",
    "                        if key == \"Elevation\":\n",
    "                            # Remove units like MASL, ASL, and clean up the value\n",
    "                            value = re.sub(r\"[^\\d\\s,-]\", \"\", value).strip()\n",
    "\n",
    "                        # Remove redundant spaces and clean up\n",
    "                        value = re.sub(r\"\\s{2,}\", \" \", value).strip()\n",
    "                        row[key] = value\n",
    "\n",
    "                # Remove dropped columns from the row\n",
    "                for col in columns_to_drop:\n",
    "                    if col in row:\n",
    "                        del row[col]\n",
    "\n",
    "                # Write the cleaned row to the output file\n",
    "                writer.writerow(row)\n",
    "\n",
    "# Example usage\n",
    "input_file = \"products_with_details.csv\"\n",
    "output_file = \"cowpresso.csv\"\n",
    "clean_csv(input_file, output_file)\n",
    "print(f\"Cleaned CSV written to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
