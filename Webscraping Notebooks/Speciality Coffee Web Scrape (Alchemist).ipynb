{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4eb18164-8963-489b-a8da-bc0dc8f98651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Card data successfully written to card_data.csv\n",
      "Variant data successfully written to variant_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# Base URLs\n",
    "collection_url = \"https://alchemist.global/collections/coffee-beans\"\n",
    "\n",
    "# Headers to mimic a browser visit\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Output CSV file names\n",
    "card_data_file = \"card_data.csv\"\n",
    "variant_data_file = \"variant_data.csv\"\n",
    "\n",
    "# Request the collection page content\n",
    "response = requests.get(collection_url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all product cards\n",
    "product_cards = soup.find_all(\"div\", class_=\"product-card-wrapper\")\n",
    "\n",
    "# Prepare card data\n",
    "card_data = []\n",
    "\n",
    "for card in product_cards:\n",
    "    # Extract product details\n",
    "    title_element = card.find(\"a\", class_=\"h5\")\n",
    "    title = title_element.text.strip() if title_element else \"N/A\"\n",
    "\n",
    "    product_url = title_element[\"href\"] if title_element else \"N/A\"\n",
    "    product_url = f\"https://alchemist.global{product_url}\"\n",
    "\n",
    "    blend_origin = card.find(\"p\", class_=\"p4 c-blue opacity-4 mb-10\")\n",
    "    blend_origin_text = blend_origin.text.strip() if blend_origin else \"N/A\"\n",
    "\n",
    "    description_element = card.find(\"div\", class_=\"short-description\")\n",
    "    description = description_element.text.strip() if description_element else \"N/A\"\n",
    "\n",
    "    # Tasting notes\n",
    "    tasting_notes = []\n",
    "    tasting_note_elements = card.find_all(\"div\", class_=\"flex ai-center mr-10\")\n",
    "    for note in tasting_note_elements:\n",
    "        note_text = note.find(\"span\", class_=\"p3\").text.strip()\n",
    "        tasting_notes.append(note_text)\n",
    "\n",
    "    price_element = card.find(\"span\", class_=\"applied-price h7\")\n",
    "    price = price_element.text.strip() if price_element else \"N/A\"\n",
    "\n",
    "    # Primary image\n",
    "    primary_image = card.find(\"img\", class_=\"image\")\n",
    "    primary_image_url = f\"https:{primary_image['data-src']}\" if primary_image else \"N/A\"\n",
    "\n",
    "    # Add to card data\n",
    "    card_data.append({\n",
    "        \"Title\": title,\n",
    "        \"Product URL\": product_url,\n",
    "        \"Blend Origin\": blend_origin_text,\n",
    "        \"Description\": description,\n",
    "        \"Tasting Notes\": \", \".join(tasting_notes),\n",
    "        \"Price\": price,\n",
    "        \"Image URL\": primary_image_url,\n",
    "    })\n",
    "\n",
    "# Write card data to CSV\n",
    "if card_data:\n",
    "    with open(card_data_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        fieldnames = [\"Title\", \"Product URL\", \"Blend Origin\", \"Description\", \"Tasting Notes\", \"Price\", \"Image URL\"]\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "        # Write header and rows\n",
    "        writer.writeheader()\n",
    "        writer.writerows(card_data)\n",
    "\n",
    "    print(f\"Card data successfully written to {card_data_file}\")\n",
    "else:\n",
    "    print(\"No card data to write to CSV\")\n",
    "\n",
    "# Step 2: Extract and process the meta JSON for variants\n",
    "variant_data = []\n",
    "meta_data_script = soup.find(\"script\", string=lambda t: t and \"var meta =\" in t)\n",
    "if meta_data_script:\n",
    "    # Extract the JSON text\n",
    "    meta_data_text = meta_data_script.string\n",
    "\n",
    "    # Isolate the JSON object by finding the first valid curly brace\n",
    "    start_index = meta_data_text.find('{\"products\":')  # Find the start of the JSON\n",
    "    end_index = meta_data_text.rfind(\"};\") + 1          # Find the last closing brace\n",
    "    valid_json_text = meta_data_text[start_index:end_index]\n",
    "\n",
    "    try:\n",
    "        meta = json.loads(valid_json_text)  # Parse the isolated JSON\n",
    "        for product in meta.get(\"products\", []):\n",
    "            product_title = product.get(\"vendor\", \"N/A\")\n",
    "            product_type = product.get(\"type\", \"N/A\")\n",
    "            product_id = product.get(\"id\", \"N/A\")\n",
    "\n",
    "            for variant in product.get(\"variants\", []):\n",
    "                variant_price = variant.get(\"price\", 0) / 100\n",
    "                variant_name = variant.get(\"name\", \"N/A\")\n",
    "                variant_url = f\"https://alchemist.global/products/{product_id}\"\n",
    "\n",
    "                # Add variant data\n",
    "                variant_data.append({\n",
    "                    \"Title\": f\"{product_title} - {variant_name}\",\n",
    "                    \"Product URL\": variant_url,\n",
    "                    \"Product Type\": product_type,\n",
    "                    \"Price (SGD)\": f\"S${variant_price:.2f}\"\n",
    "                })\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "# Write variant data to CSV\n",
    "if variant_data:\n",
    "    with open(variant_data_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        fieldnames = [\"Title\", \"Product URL\", \"Product Type\", \"Price (SGD)\"]\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "        # Write header and rows\n",
    "        writer.writeheader()\n",
    "        writer.writerows(variant_data)\n",
    "\n",
    "    print(f\"Variant data successfully written to {variant_data_file}\")\n",
    "else:\n",
    "    print(\"No variant data to write to CSV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e3b26e1a-e31a-4801-ba3b-4ada065ba1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed data saved to compressed_alchemist_coffee_products.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"alchemist_coffee_products.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Group by 'Product URL' or another unique identifier\n",
    "compressed_df = df.groupby(\"Product URL\").agg({\n",
    "    \"Title\": \"first\",  # Use the first non-null Title\n",
    "    \"Blend Origin\": \"first\",  # Use the first non-null Blend Origin\n",
    "    \"Description\": \"first\",  # Use the first non-null Description\n",
    "    \"Tasting Notes\": lambda x: \", \".join(x.dropna().unique()),  # Combine unique Tasting Notes\n",
    "    \"Price\": lambda x: \", \".join(x.dropna().unique()),  # Combine unique Prices\n",
    "    \"Image URL\": \"first\",  # Use the first non-null Image URL\n",
    "    \"Price (SGD)\": lambda x: \", \".join(x.dropna().unique()),  # Combine unique Prices in SGD\n",
    "}).reset_index()\n",
    "\n",
    "# Save the compressed data back to a CSV file\n",
    "output_path = \"compressed_alchemist_coffee_products.csv\"\n",
    "compressed_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Compressed data saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
