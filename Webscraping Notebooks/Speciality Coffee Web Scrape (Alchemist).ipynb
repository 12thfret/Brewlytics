{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4eb18164-8963-489b-a8da-bc0dc8f98651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final combined data written to final_output.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "# Base URL for the collection\n",
    "COLLECTION_URL = \"https://alchemist.global/collections/coffee-beans\"\n",
    "\n",
    "# Headers to mimic a browser visit\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/89.0.4389.82 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Final CSV file name\n",
    "FINAL_OUTPUT_FILE = \"final_output.csv\"\n",
    "\n",
    "# ----- UTILITY FUNCTIONS -----\n",
    "\n",
    "def extract_weight_and_brewing(title):\n",
    "    \"\"\"\n",
    "    Extract weight (e.g., '150g', '200g') and brewing type (e.g., 'Filter', 'Espresso')\n",
    "    from the end of a variant title.\n",
    "    \n",
    "    Expected format (at the end of the string):\n",
    "        \"Filter / 150g\"\n",
    "        \"Espresso / 200g\"\n",
    "        \n",
    "    Returns a tuple: (weight, brewing_type) or (\"N/A\", \"N/A\") if not found.\n",
    "    \"\"\"\n",
    "    # Look for \"Filter\" or \"Espresso\" followed by a slash and weight at the end.\n",
    "    pattern = r'(Filter|Espresso)\\s*/\\s*(\\d+\\s?[gG])$'\n",
    "    match = re.search(pattern, title, re.IGNORECASE)\n",
    "    if match:\n",
    "        brewing_type = match.group(1).title()  # Normalize to title case\n",
    "        weight = match.group(2).lower()\n",
    "        return weight, brewing_type\n",
    "    return \"N/A\", \"N/A\"\n",
    "\n",
    "def similar(a, b):\n",
    "    \"\"\"Return a similarity score between two strings.\"\"\"\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# ----- SCRAPE CARD DATA -----\n",
    "\n",
    "def scrape_card_data():\n",
    "    \"\"\"\n",
    "    Scrape card data from the collection page.\n",
    "    Returns a list of dictionaries with keys:\n",
    "      Card Title, Card Product URL, Blend Origin, Description, Tasting Notes, Image URL.\n",
    "    \"\"\"\n",
    "    response = requests.get(COLLECTION_URL, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    product_cards = soup.find_all(\"div\", class_=\"product-card-wrapper\")\n",
    "    \n",
    "    card_data_list = []\n",
    "    for card in product_cards:\n",
    "        # Card Title\n",
    "        title_element = card.find(\"a\", class_=\"h5\")\n",
    "        card_title = title_element.text.strip() if title_element else \"N/A\"\n",
    "        \n",
    "        # Card Product URL\n",
    "        product_url = title_element[\"href\"] if title_element else \"N/A\"\n",
    "        if product_url != \"N/A\":\n",
    "            product_url = f\"https://alchemist.global{product_url}\"\n",
    "        \n",
    "        # Blend Origin\n",
    "        blend_origin_elem = card.find(\"p\", class_=\"p4 c-blue opacity-4 mb-10\")\n",
    "        blend_origin = blend_origin_elem.text.strip() if blend_origin_elem else \"N/A\"\n",
    "        \n",
    "        # Description\n",
    "        description_elem = card.find(\"div\", class_=\"short-description\")\n",
    "        description = description_elem.text.strip() if description_elem else \"N/A\"\n",
    "        \n",
    "        # Tasting Notes\n",
    "        tasting_notes = []\n",
    "        tasting_note_elems = card.find_all(\"div\", class_=\"flex ai-center mr-10\")\n",
    "        for note in tasting_note_elems:\n",
    "            note_span = note.find(\"span\", class_=\"p3\")\n",
    "            if note_span:\n",
    "                tasting_notes.append(note_span.text.strip())\n",
    "        tasting_notes_str = \", \".join(tasting_notes)\n",
    "        \n",
    "        # Image URL\n",
    "        primary_image = card.find(\"img\", class_=\"image\")\n",
    "        if primary_image and primary_image.get(\"data-src\"):\n",
    "            image_url = f\"https:{primary_image['data-src']}\"\n",
    "        else:\n",
    "            image_url = \"N/A\"\n",
    "        \n",
    "        card_data_list.append({\n",
    "            \"Card Title\": card_title,\n",
    "            \"Card Product URL\": product_url,\n",
    "            \"Blend Origin\": blend_origin,\n",
    "            \"Description\": description,\n",
    "            \"Tasting Notes\": tasting_notes_str,\n",
    "            \"Image URL\": image_url\n",
    "        })\n",
    "    return card_data_list\n",
    "\n",
    "# ----- SCRAPE VARIANT DATA -----\n",
    "\n",
    "def scrape_variant_data():\n",
    "    \"\"\"\n",
    "    Scrape variant data from the meta JSON embedded on the page.\n",
    "    Returns a list of dictionaries with keys:\n",
    "      Variant Title, Weight, Brewing Type, Variant Product URL, Variant Price.\n",
    "    \"\"\"\n",
    "    response = requests.get(COLLECTION_URL, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    variant_data_list = []\n",
    "    meta_script = soup.find(\"script\", string=lambda t: t and \"var meta =\" in t)\n",
    "    if meta_script:\n",
    "        meta_text = meta_script.string\n",
    "        start_index = meta_text.find('{\"products\":')\n",
    "        end_index = meta_text.rfind(\"};\") + 1\n",
    "        valid_json_text = meta_text[start_index:end_index]\n",
    "        \n",
    "        try:\n",
    "            meta = json.loads(valid_json_text)\n",
    "            for product in meta.get(\"products\", []):\n",
    "                product_id = product.get(\"id\", \"N/A\")\n",
    "                vendor = product.get(\"vendor\", \"N/A\")\n",
    "                for variant in product.get(\"variants\", []):\n",
    "                    variant_name = variant.get(\"name\", \"N/A\")\n",
    "                    variant_price_cents = variant.get(\"price\", 0)\n",
    "                    variant_price_sgd = variant_price_cents / 100.0\n",
    "                    \n",
    "                    # Extract weight and brewing type from the variant title\n",
    "                    weight, brewing_type = extract_weight_and_brewing(variant_name)\n",
    "                    \n",
    "                    # Combine vendor with variant name for fuzzy matching\n",
    "                    full_variant_title = f\"{vendor} - {variant_name}\"\n",
    "                    variant_url = f\"https://alchemist.global/products/{product_id}\"\n",
    "                    \n",
    "                    variant_data_list.append({\n",
    "                        \"Variant Title\": full_variant_title,\n",
    "                        \"Weight\": weight,\n",
    "                        \"Brewing Type\": brewing_type,\n",
    "                        \"Variant Product URL\": variant_url,\n",
    "                        \"Variant Price\": f\"S${variant_price_sgd:.2f}\"\n",
    "                    })\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "    return variant_data_list\n",
    "\n",
    "# ----- FUZZY MATCH & FINAL OUTPUT -----\n",
    "\n",
    "def create_final_output():\n",
    "    \"\"\"\n",
    "    Fuzzy match each card's title with the best variant's title.\n",
    "    Final output includes:\n",
    "      Card Title, Variant Data Weight, Variant Data Brewing Type, Variant Price,\n",
    "      Card Product URL, Blend Origin, Description, Tasting Notes, Image URL.\n",
    "    \"\"\"\n",
    "    card_data = scrape_card_data()\n",
    "    variant_data = scrape_variant_data()\n",
    "    \n",
    "    final_rows = []\n",
    "    for card in card_data:\n",
    "        card_title = card[\"Card Title\"]\n",
    "        best_match = None\n",
    "        highest_score = 0.0\n",
    "        \n",
    "        for variant in variant_data:\n",
    "            score = similar(card_title.lower(), variant[\"Variant Title\"].lower())\n",
    "            if score > highest_score:\n",
    "                highest_score = score\n",
    "                best_match = variant\n",
    "        \n",
    "        if best_match and highest_score > 0.2:\n",
    "            weight = best_match[\"Weight\"]\n",
    "            brewing_type = best_match[\"Brewing Type\"]\n",
    "            variant_price = best_match[\"Variant Price\"]\n",
    "        else:\n",
    "            weight = \"N/A\"\n",
    "            brewing_type = \"N/A\"\n",
    "            variant_price = \"N/A\"\n",
    "        \n",
    "        final_rows.append({\n",
    "            \"Card Title\": card_title,\n",
    "            \"Weight\": weight,\n",
    "            \"Brewing Type\": brewing_type,\n",
    "            \"Variant Price\": variant_price,\n",
    "            \"Card Product URL\": card[\"Card Product URL\"],\n",
    "            \"Blend Origin\": card[\"Blend Origin\"],\n",
    "            \"Description\": card[\"Description\"],\n",
    "            \"Tasting Notes\": card[\"Tasting Notes\"],\n",
    "            \"Image URL\": card[\"Image URL\"]\n",
    "        })\n",
    "    return final_rows\n",
    "\n",
    "def generate_final_csv():\n",
    "    \"\"\"\n",
    "    Generate the final CSV content from the combined data.\n",
    "    Returns a CSV string.\n",
    "    \"\"\"\n",
    "    final_data = create_final_output()\n",
    "    fieldnames = [\n",
    "        \"Card Title\", \"Weight\", \"Brewing Type\", \"Variant Price\", \"Card Product URL\",\n",
    "        \"Blend Origin\", \"Description\", \"Tasting Notes\", \"Image URL\"\n",
    "    ]\n",
    "    \n",
    "    output = io.StringIO()\n",
    "    writer = csv.DictWriter(output, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(final_data)\n",
    "    csv_content = output.getvalue()\n",
    "    output.close()\n",
    "    return csv_content\n",
    "\n",
    "# ----- WRITE FINAL CSV TO FILE (LOCAL TESTING) -----\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_output = generate_final_csv()\n",
    "    with open(FINAL_OUTPUT_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        f.write(csv_output)\n",
    "    print(f\"Final combined data written to {FINAL_OUTPUT_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
