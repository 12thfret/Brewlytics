{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4810b57e-d9bc-455a-9d09-33022d01cd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to coffee_products_with_variants.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# Base URLs\n",
    "collection_url = \"https://nylon.coffee/collections/coffee\"\n",
    "product_base_url = \"https://nylon.coffee/products/\"\n",
    "\n",
    "# Headers to mimic a browser visit\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Output CSV file name\n",
    "output_file = \"coffee_products_with_variants.csv\"\n",
    "\n",
    "# Step 1: Scrape the collection page to get product handles\n",
    "response = requests.get(collection_url, headers=headers)\n",
    "collection_soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "product_cards = collection_soup.find_all(\"product-card\")\n",
    "\n",
    "# Prepare data for CSV\n",
    "products_data = []\n",
    "\n",
    "for card in product_cards:\n",
    "    # Extract collection-level details\n",
    "    handle = card.get(\"handle\", \"N/A\")\n",
    "    primary_image = card.find(\"img\", class_=\"product-card__image--primary\")\n",
    "    primary_image_url = f\"https:{primary_image['src']}\" if primary_image else \"N/A\"\n",
    "    sold_out_badge = card.find(\"sold-out-badge\")\n",
    "    is_sold_out = sold_out_badge.text.strip() if sold_out_badge else \"In Stock\"\n",
    "    tasting_notes_element = card.find(\"div\", class_=\"product-tasting\")\n",
    "    tasting_notes = tasting_notes_element.text.strip() if tasting_notes_element else \"N/A\"\n",
    "\n",
    "    # Step 2: Visit product page for additional details\n",
    "    product_url = f\"{product_base_url}{handle}\"\n",
    "    product_response = requests.get(product_url, headers=headers)\n",
    "    product_soup = BeautifulSoup(product_response.text, \"html.parser\")\n",
    "\n",
    "    # Extract feature chart\n",
    "    feature_chart = product_soup.find(\"div\", class_=\"feature-chart__table\")\n",
    "    features = {}\n",
    "    if feature_chart:\n",
    "        rows = feature_chart.find_all(\"div\", class_=\"feature-chart__table-row\")\n",
    "        for row in rows:\n",
    "            heading = row.find(\"div\", class_=\"feature-chart__heading\")\n",
    "            value = row.find(\"div\", class_=\"feature-chart__value\")\n",
    "            if heading and value:\n",
    "                features[heading.text.strip()] = value.text.strip()\n",
    "\n",
    "    # Extract product variants\n",
    "    script_tag = product_soup.find(\"script\", type=\"application/ld+json\")\n",
    "    variants = []\n",
    "    if script_tag:\n",
    "        product_data_json = json.loads(script_tag.string)\n",
    "        if \"hasVariant\" in product_data_json:\n",
    "            for variant in product_data_json[\"hasVariant\"]:\n",
    "                variant_data = {\n",
    "                    \"Variant Name\": variant.get(\"name\", \"N/A\"),\n",
    "                    \"Variant Price\": variant.get(\"offers\", {}).get(\"price\", \"N/A\"),\n",
    "                    \"Variant Availability\": variant.get(\"offers\", {}).get(\"availability\", \"N/A\"),\n",
    "                }\n",
    "                variants.append(variant_data)\n",
    "\n",
    "    # If variants exist, add them and skip the base product\n",
    "    if variants:\n",
    "        for variant in variants:\n",
    "            variant_data = {\n",
    "                \"Handle\": handle,\n",
    "                \"Primary Image URL\": primary_image_url,\n",
    "                \"Availability\": is_sold_out,\n",
    "                \"Tasting Notes\": tasting_notes,\n",
    "            }\n",
    "            variant_data.update(features)\n",
    "            variant_data.update(variant)\n",
    "            products_data.append(variant_data)\n",
    "    else:\n",
    "        # If no variants, include the base product with price\n",
    "        price_element = product_soup.find(\"meta\", {\"property\": \"product:price:amount\"})\n",
    "        base_price = price_element[\"content\"] if price_element else \"N/A\"\n",
    "        base_product_data = {\n",
    "            \"Handle\": handle,\n",
    "            \"Primary Image URL\": primary_image_url,\n",
    "            \"Availability\": is_sold_out,\n",
    "            \"Tasting Notes\": tasting_notes,\n",
    "            \"Variant Name\": \"Base Product\",\n",
    "            \"Variant Price\": base_price,\n",
    "            \"Variant Availability\": is_sold_out,\n",
    "        }\n",
    "        base_product_data.update(features)\n",
    "        products_data.append(base_product_data)\n",
    "\n",
    "# Write data to CSV\n",
    "with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    # Determine CSV fieldnames from keys of the first product_data entry\n",
    "    fieldnames = list(products_data[0].keys())\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "    # Write header and rows\n",
    "    writer.writeheader()\n",
    "    writer.writerows(products_data)\n",
    "\n",
    "print(f\"Data successfully written to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
